# main.py
# -*- coding: utf-8 -*-

"""
Single output: LLM-based profile only (summary -> MBTI/Big5/Socionics)
- Compatible with OpenAI Python SDKs that do NOT support response_format=json_schema.

Input:
- KakaoTalk exported .txt
- --name: the user's speaker name in the export
- --user_id: your internal id (DB PK or uuid)

Output:
- One JSON object:
  - meta
  - parse_quality
  - llm_profile (summary + MBTI/Big5/Socionics + reasons + caveats)

Install:
  pip install openai python-dotenv

Env (.env):
  OPENAI_API_KEY=...
  OPENAI_MODEL=...

Usage:
  python main.py --file sample_chat.txt --name "í™ê¸¸ë™" --user_id "u_123" --out profile.json
"""

import argparse
import json
import os
import re
from dataclasses import dataclass, asdict
from datetime import datetime
from typing import Dict, List, Tuple

from dotenv import load_dotenv
from openai import OpenAI


# ----------------------------
# Kakao parsing patterns
# ----------------------------
LINE_PATTERNS = [
    re.compile(r"^\[(?P<name>.+?)\]\s+\[(?P<time>.+?)\]\s+(?P<msg>.+)$"),
    re.compile(r"^(?P<time>\d{4}\.\s*\d{1,2}\.\s*\d{1,2}\.\s*.+?),\s*(?P<name>[^:]+?)\s*:\s*(?P<msg>.+)$"),
]

SYSTEM_SKIP_SUBSTR = [
    "ì‚¬ì§„", "ì´ëª¨í‹°ì½˜", "ë™ì˜ìƒ", "ì‚­ì œëœ ë©”ì‹œì§€ì…ë‹ˆë‹¤", "íŒŒì¼", "ë³´ì´ìŠ¤í†¡", "í†µí™”",
    "ì†¡ê¸ˆ", "ì…ê¸ˆ", "ì¶œê¸ˆ",
]

RE_URL = re.compile(r"https?://\S+")
RE_LAUGH = re.compile(r"[ã…‹ã…]{2,}")
RE_CRY = re.compile(r"[ã… ã…œ]{2,}")
RE_SPACES = re.compile(r"\s+")

RE_PHONE = re.compile(r"(01[016789])[-.\s]?\d{3,4}[-.\s]?\d{4}")
RE_EMAIL = re.compile(r"\b[a-zA-Z0-9._%+\-]+@[a-zA-Z0-9.\-]+\.[a-zA-Z]{2,}\b")
RE_KR_ID = re.compile(r"\b\d{6}[-\s]?\d{7}\b")

RE_QUESTION = re.compile(r"\?")
RE_EMO = re.compile(r"(?:\:\)|\:\(|\^\^|ã…ã…|ã…‹|ã… |ã…œ|ğŸ˜„|ğŸ˜‚|ğŸ˜­|ğŸ™‚|ğŸ™ƒ|ğŸ˜…|ğŸ˜¢)")


# ----------------------------
# Data structures
# ----------------------------
@dataclass
class ParseQuality:
    total_lines: int
    parsed_lines: int
    parse_failed_lines: int
    filtered_system_lines: int
    empty_text_lines: int
    pii_masked_hits: int


# ----------------------------
# Helpers
# ----------------------------
def looks_like_system_message(text: str) -> bool:
    t = text.strip()
    if not t:
        return True
    return any(s in t for s in SYSTEM_SKIP_SUBSTR)


def clean_text_ko(text: str) -> str:
    text = RE_URL.sub(" ", text)
    text = RE_LAUGH.sub(" ", text)
    text = RE_CRY.sub(" ", text)
    text = RE_SPACES.sub(" ", text).strip()
    return text


def mask_pii(text: str) -> Tuple[str, int]:
    hits = 0

    new = RE_PHONE.sub("[ì „í™”ë²ˆí˜¸]", text)
    if new != text:
        hits += 1
    text = new

    new = RE_EMAIL.sub("[ì´ë©”ì¼]", text)
    if new != text:
        hits += 1
    text = new

    new = RE_KR_ID.sub("[ì£¼ë¯¼ë²ˆí˜¸]", text)
    if new != text:
        hits += 1
    text = new

    return text, hits


# ----------------------------
# Parse TXT and filter only target user
# ----------------------------
def parse_target_rows(filepath: str, target_name: str) -> Tuple[List[Dict[str, str]], ParseQuality]:
    total_lines = parsed = failed = filtered_system = empty_text = pii_hits_total = 0
    rows: List[Dict[str, str]] = []

    with open(filepath, "r", encoding="utf-8", errors="ignore") as f:
        for raw in f:
            total_lines += 1
            line = raw.rstrip("\n")
            if not line.strip():
                failed += 1
                continue

            m = None
            for pat in LINE_PATTERNS:
                m = pat.match(line)
                if m:
                    break
            if not m:
                failed += 1
                continue

            speaker = m.group("name").strip()
            if speaker != target_name:
                continue

            text = m.group("msg").strip()

            if looks_like_system_message(text):
                filtered_system += 1
                continue

            text = clean_text_ko(text)
            if not text:
                empty_text += 1
                continue

            text, hits = mask_pii(text)
            pii_hits_total += hits

            rows.append({"text": text})
            parsed += 1

    quality = ParseQuality(
        total_lines=total_lines,
        parsed_lines=parsed,
        parse_failed_lines=failed,
        filtered_system_lines=filtered_system,
        empty_text_lines=empty_text,
        pii_masked_hits=pii_hits_total,
    )
    return rows, quality


# ----------------------------
# Numeric signals (minimal)
# ----------------------------
def compute_numeric_signals(rows: List[Dict[str, str]]) -> Dict[str, float]:
    texts = [r["text"] for r in rows]
    n = max(len(texts), 1)

    avg_msg_len = sum(len(t) for t in texts) / n
    question_ratio = sum(1 for t in texts if RE_QUESTION.search(t)) / n
    emoji_ratio = sum(1 for t in texts if RE_EMO.search(t)) / n

    return {
        "message_count": float(len(rows)),
        "avg_msg_len": float(avg_msg_len),
        "question_ratio": float(question_ratio),
        "emoji_ratio": float(emoji_ratio),
    }


def sample_texts_for_llm(rows: List[Dict[str, str]], max_msgs: int, max_chars: int) -> List[str]:
    if not rows:
        return []

    n = len(rows)
    if n <= max_msgs:
        pick = rows
    else:
        step = max(1, n // max_msgs)
        pick = [rows[i] for i in range(0, n, step)][:max_msgs]

    out: List[str] = []
    total = 0
    for r in pick:
        t = r["text"].strip()
        if not t:
            continue
        if len(t) > 180:
            t = t[:180] + "â€¦"
        if total + len(t) + 1 > max_chars:
            break
        out.append(t)
        total += len(t) + 1
    return out


# ----------------------------
# LLM call (SDK-compatible, no response_format)
# ----------------------------
def _extract_responses_text(resp) -> str:
    """
    Responses API ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ìµœëŒ€í•œ ì•ˆì „í•˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    SDK ë²„ì „ì— ë”°ë¼ resp.output_textê°€ ì—†ê±°ë‚˜ resp.output êµ¬ì¡°ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ ë°©ì–´ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    if hasattr(resp, "output_text") and resp.output_text:
        return resp.output_text

    texts: List[str] = []

    for item in getattr(resp, "output", []) or []:
        for c in getattr(item, "content", []) or []:
            t = None
            if hasattr(c, "text"):
                t = c.text
            elif isinstance(c, dict):
                t = c.get("text")
            if t:
                texts.append(t)

    if not texts and isinstance(resp, dict):
        if resp.get("output_text"):
            return resp["output_text"]
        out = resp.get("output", [])
        for item in out:
            for c in item.get("content", []) or []:
                if isinstance(c, dict) and c.get("text"):
                    texts.append(c["text"])

    return "\n".join(texts).strip()


def _extract_json_object(raw: str) -> Dict[str, object]:
    raw = (raw or "").strip()
    if not raw:
        raise RuntimeError("LLM ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    try:
        obj = json.loads(raw)
        if not isinstance(obj, dict):
            raise RuntimeError("LLMì´ JSON ê°ì²´(dict)ê°€ ì•„ë‹Œ ê°’ì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")
        return obj
    except json.JSONDecodeError:
        pass

    l = raw.find("{")
    r = raw.rfind("}")
    if l != -1 and r != -1 and r > l:
        candidate = raw[l:r + 1]
        try:
            obj = json.loads(candidate)
            if not isinstance(obj, dict):
                raise RuntimeError("LLMì´ JSON ê°ì²´(dict)ê°€ ì•„ë‹Œ ê°’ì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")
            return obj
        except json.JSONDecodeError:
            pass

    raise RuntimeError(
        "LLMì´ JSONìœ¼ë¡œ íŒŒì‹± ë¶ˆê°€ëŠ¥í•œ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.\n"
        "--- RAW START ---\n" + raw + "\n--- RAW END ---"
    )


def call_llm_profile(client: OpenAI, model: str, llm_input: Dict[str, object]) -> Dict[str, object]:
    """
    response_format(json_schema)ì„ ì§€ì›í•˜ì§€ ì•ŠëŠ” SDKì—ì„œë„ ë™ì‘í•˜ëŠ” ë²„ì „.
    - JSON Schema ê°•ì œ ëŒ€ì‹ : í”„ë¡¬í”„íŠ¸ë¡œ 'JSONë§Œ' ë°˜í™˜í•˜ë„ë¡ ê°•ì œ
    - ì¶œë ¥ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ í›„ json.loads íŒŒì‹±
    """

    json_contract = {
        "summary": {
            "one_paragraph": "string",
            "communication_style_bullets": ["string", "..."]
        },
        "mbti": {
            "type": "I/E + N/S + F/T + J/P (ì˜ˆ: INTJ)",
            "confidence": "0~1 number",
            "reasons": ["string", "..."]
        },
        "big5": {
            "scores_0_100": {
                "openness": "0~100",
                "conscientiousness": "0~100",
                "extraversion": "0~100",
                "agreeableness": "0~100",
                "neuroticism": "0~100"
            },
            "confidence": "0~1 number",
            "reasons": ["Trait: reason string...", "..."]
        },
        "socionics": {
            "type": "string (ì˜ˆ: LII, EII, SLE ë“±)",
            "confidence": "0~1 number",
            "reasons": ["string", "..."]
        },
        "caveats": ["string", "..."]
    }

    system = (
        "ë‹¹ì‹ ì€ ëŒ€í™” ìš”ì•½/ì„±í–¥ ì¶”ì • ë„ìš°ë¯¸ì…ë‹ˆë‹¤.\n"
        "ì¤‘ìš”:\n"
        "- ì›ë¬¸ ëŒ€í™” ë¬¸ì¥ì„ ì§ì ‘ ì¸ìš©(ë”°ì˜´í‘œ í¬í•¨)í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.\n"
        "- ê°œì¸ì •ë³´/ì‹ë³„ì •ë³´ë¥¼ ìƒì„±í•˜ê±°ë‚˜ ì¶”ì¸¡í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.\n"
        "- ëŒ€í™”ë°© ê·œë²”ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆëŠ” ë§íˆ¬(ì¡´ëŒ“ë§/ë°˜ë§/ì™„ê³¡ í‘œí˜„ ë“±)ë¥¼ ê·¼ê±°ë¡œ ì‚¼ì§€ ë§ˆì‹­ì‹œì˜¤.\n"
        "- ì œê³µëœ ìƒ˜í”Œ(ì •ì œÂ·ë§ˆìŠ¤í‚¹ë¨)ê³¼ ìˆ˜ì¹˜ ì‹ í˜¸(í‰ê·  ê¸¸ì´/ì§ˆë¬¸ë¹„ìœ¨/ì´ëª¨ì§€ë¹„ìœ¨ ë“±)ë§Œìœ¼ë¡œ "
        "MBTI, Big5, ì†Œì‹œì˜¤ë‹ˆí¬ë¥¼ 'ì¶”ì •'í•˜ê³  ì´ìœ ë¥¼ í•œêµ­ì–´ë¡œ ì œì‹œí•˜ì‹­ì‹œì˜¤.\n"
        "- í•œê³„ì™€ ì˜¤ì°¨ ê°€ëŠ¥ì„±ì„ caveatsì— ë°˜ë“œì‹œ í¬í•¨í•˜ì‹­ì‹œì˜¤.\n\n"
        "Big5 ì´ìœ  (reasons) ì‘ì„±:\n"
        "- ê° íŠ¹ì„±(Openness, Conscientiousness, Extraversion, Agreeableness, Neuroticism)ë§ˆë‹¤ "
        "'íŠ¹ì„±ëª…: êµ¬ì²´ì ì¸ ì´ìœ ' í˜•ì‹ì˜ ë¬¸ì¥ì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤.\n"
        "- ì˜ˆì‹œ: 'Openness: ìƒˆë¡œìš´ í‘œí˜„ê³¼ ì‹¤í—˜ì ì¸ ì–¸ì–´ ì‚¬ìš©ì´ ë¹ˆë²ˆí•¨', "
        "'Conscientiousness: ê³„íšì ì´ê³  ì‹œê°„ ì•½ì†ì„ ì—„ê²©íˆ ì§€í‚¤ëŠ” ì–¸ì–´ íŒ¨í„´'\n"
        "- ìµœì†Œ 3~5ê°œì˜ ëª…í™•í•œ ì´ìœ ë¥¼ reasons ë°°ì—´ì— í¬í•¨í•˜ì‹­ì‹œì˜¤.\n\n"
        "ì¶œë ¥ í˜•ì‹ ìš”êµ¬ì‚¬í•­:\n"
        "- ë°˜ë“œì‹œ JSON 'ê°ì²´' í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.\n"
        "- ì„¤ëª… ë¬¸ì¥/ë§ˆí¬ë‹¤ìš´/ì½”ë“œë¸”ë¡/ì—¬ë¶„ í…ìŠ¤íŠ¸ë¥¼ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.\n"
        "- í‚¤ ì´ë¦„ì€ ì•„ë˜ ê³„ì•½(json_contract)ê³¼ ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤."
    )

    user = {
        "task": "Infer MBTI/Big5/Socionics from chat samples + numeric signals.",
        "json_contract": json_contract,
        "input": llm_input
    }

    # IMPORTANT: response_format ì œê±° (SDK í˜¸í™˜)
    resp = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": json.dumps(user, ensure_ascii=False)}
        ]
    )

    raw = _extract_responses_text(resp)
    obj = _extract_json_object(raw)

    required = ["summary", "mbti", "big5", "socionics", "caveats"]
    for k in required:
        if k not in obj:
            raise RuntimeError(f"LLM JSON ê²°ê³¼ì— í•„ìˆ˜ í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤: {k}")

    return obj


# ----------------------------
# CLI
# ----------------------------
def main():
    ap = argparse.ArgumentParser(description="Single-output LLM profiling from KakaoTalk TXT")
    ap.add_argument("--file", required=True, help="KakaoTalk exported .txt file path")
    ap.add_argument("--name", required=True, help="Target speaker name in the export (the uploader)")
    ap.add_argument("--user_id", required=True, help="Your internal user id (DB PK/UUID)")
    ap.add_argument("--out", default="", help="Output JSON path (optional)")
    ap.add_argument("--min_msgs", type=int, default=30, help="Minimum messages required (default: 30)")
    ap.add_argument("--openai_model", default=os.getenv("OPENAI_MODEL", "gpt-5-mini"))
    ap.add_argument("--max_msgs_for_llm", type=int, default=120)
    ap.add_argument("--max_chars_for_llm", type=int, default=18000)

    args = ap.parse_args()

    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY", "")
    if not api_key:
        raise SystemExit("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ì„¸ìš”.")

    rows, quality = parse_target_rows(args.file, args.name)
    if len(rows) < args.min_msgs:
        raise SystemExit(
            f"ë¶„ì„ ê°€ëŠ¥í•œ ë°œí™”ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤: {len(rows)}ê°œ (< {args.min_msgs}). "
            f"--name(ëŒ€í™”ëª…) ë˜ëŠ” --min_msgsë¥¼ í™•ì¸í•˜ì„¸ìš”."
        )

    signals = compute_numeric_signals(rows)
    samples = sample_texts_for_llm(rows, max_msgs=args.max_msgs_for_llm, max_chars=args.max_chars_for_llm)

    llm_input = {
        "samples": samples,
        "numeric_signals": signals,
        "constraints": {
            "no_quotes": True,
            "no_pii": True,
            "avoid_room_dependent_style": True
        }
    }

    client = OpenAI(api_key=api_key)
    profile = call_llm_profile(client=client, model=args.openai_model, llm_input=llm_input)

    out_obj = {
        "meta": {
            "source": "kakao_export_txt",
            "generated_at_utc": datetime.utcnow().isoformat() + "Z",
            "file": args.file,
            "speaker_name": args.name,
            "user_id": args.user_id,
            "model": args.openai_model
        },
        "parse_quality": asdict(quality),
        "llm_profile": profile
    }

    text = json.dumps(out_obj, ensure_ascii=False, indent=2)
    if args.out:
        with open(args.out, "w", encoding="utf-8") as f:
            f.write(text)
        print(f"[OK] Saved: {args.out}")
    else:
        print(text)


if __name__ == "__main__":
    main()